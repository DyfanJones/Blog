<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Dyfan Jones Brain Dump HQ</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Dyfan Jones Brain Dump HQ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Tue, 29 Oct 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Amazon SDK for R!?</title>
      <link>/post/an-amazon-sdk-for-r/</link>
      <pubDate>Tue, 29 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/an-amazon-sdk-for-r/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.r-bloggers.com&#34;&gt;RBloggers&lt;/a&gt;|&lt;a href=&#34;http://feeds.feedburner.com/RBloggers&#34;&gt;RBloggers-feedburner&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro:&lt;/h1&gt;

&lt;p&gt;For a long time I have found it difficult to leverage the benefits of cloud computer in my R model builds. This was mainly down to the initial lack of understanding of cloud compute and the setting up of R on cloud computer environments. When I noticed that AWS was bringing out a new product &lt;a href=&#34;https://aws.amazon.com/sagemaker/&#34;&gt;AWS Sagemaker&lt;/a&gt;, the possiblities of what it could provide seemed like a dream come true.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Amazon SageMaker provides every developer and data scientist with the ability to build, train, and deploy machine learning models quickly. Amazon SageMaker is a fully-managed service that covers the entire machine learning workflow to label and prepare your data, choose an algorithm, train the model, tune and optimize it for deployment, make predictions, and take action. Your models get to production faster with much less effort and lower cost. (&lt;a href=&#34;https://aws.amazon.com/sagemaker/&#34;&gt;https://aws.amazon.com/sagemaker/&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A question about AWS Sagemake came to mind: &lt;em&gt;Does it work for R developers???&lt;/em&gt; Well&amp;hellip;not exactly. True it provides a simple way set up an R environment in the cloud but it doesn&amp;rsquo;t give the means to access other AWS products for example &lt;a href=&#34;https://aws.amazon.com/s3/&#34;&gt;AWS S3&lt;/a&gt; and &lt;a href=&#34;https://aws.amazon.com/athena/&#34;&gt;AWS Athena&lt;/a&gt; out of the box. However for Python this is not a problem. Amazon has provided a Software Development Kit (SDK) for Python called &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&#34;&gt;&lt;code&gt;boto3&lt;/code&gt;&lt;/a&gt;, which comes pre-installed on AWS Sagemaker.&lt;/p&gt;

&lt;p&gt;It isn&amp;rsquo;t all bad news, RStudio has developed a package called &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;&lt;code&gt;reticulate&lt;/code&gt;&lt;/a&gt; that lets R interfaced into Python. So using &lt;code&gt;reticulate&lt;/code&gt; in combination with &lt;code&gt;boto3&lt;/code&gt; gives R full access to all of AWS products from Sagemaker similar to Python. However are there any other methods for R user to connect to AWS?&lt;/p&gt;

&lt;h1 id=&#34;aws-interfaces-for-r&#34;&gt;AWS interfaces for R:&lt;/h1&gt;

&lt;h2 id=&#34;paws-https-paws-r-github-io-an-r-sdk&#34;&gt;&lt;a href=&#34;https://paws-r.github.io/&#34;&gt;&lt;code&gt;paws&lt;/code&gt;&lt;/a&gt; an R SDK:&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Paws is a Package for Amazon Web Services in R. Paws provides access to the full suite of AWS services from within R.(&lt;a href=&#34;https://github.com/paws-r/paws&#34;&gt;https://github.com/paws-r/paws&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When I want to programatically connect to AWS I usually turn to Python. AWS&amp;rsquo;s &lt;code&gt;boto3&lt;/code&gt; is an excellent means of connecting to AWS and leverage it&amp;rsquo;s functionality. However R now has it&amp;rsquo;s own SDK into AWS, &lt;code&gt;paws&lt;/code&gt;. This came as a little surprise to me as I started to accept that R might never have an SDK for AWS. How wrong I was.&lt;/p&gt;

&lt;p&gt;What particularly shocked (pleasant shock) me was how well developed and easy the package was to use. It felt natural to switch between &lt;code&gt;boto3&lt;/code&gt; and &lt;code&gt;paws&lt;/code&gt;. Almost like it was a long lost brother.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Here is a quick example to show the comparison between &lt;code&gt;boto3&lt;/code&gt; and &lt;code&gt;paws&lt;/code&gt;. Returning a list of all objects in S3 inside a prefix:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import boto3

s3 = boto3.Session().client(&amp;quot;s3&amp;quot;)
obj = s3.list_objects(Bucket = &#39;mybucket&#39;, Prefix = &amp;quot;prefix_1/&amp;quot;)
[x.get(&amp;quot;Key&amp;quot;) for x in obj.get(&amp;quot;Contents&amp;quot;)]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s3 &amp;lt;- paws::s3()

obj &amp;lt;- s3$list_objects(Bucket = &#39;mybucket&#39;, Prefix = &amp;quot;prefix_1/&amp;quot;)
lapply(obj$Contents, function(x) x$Key)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From this quick example it is clear that the &lt;code&gt;paws&lt;/code&gt; SDK&amp;rsquo;s syntax is extremely similar to &lt;code&gt;boto3&lt;/code&gt;, although with an R twist. This can only a good thing, as hundreds of people know &lt;code&gt;boto3&lt;/code&gt; already and therefore they will be familiar with &lt;code&gt;paws&lt;/code&gt; by association. I can&amp;rsquo;t express the potential the package &lt;code&gt;paws&lt;/code&gt; gives R users. A good project that utilises the &lt;code&gt;paws&lt;/code&gt; sdk is the package &lt;a href=&#34;https://cran.r-project.org/web/packages/noctua/index.html&#34;&gt;&lt;code&gt;noctua&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;noctua&lt;/code&gt; creates a wrapper of the &lt;code&gt;paws&lt;/code&gt; connection to AWS Athena and developes a &lt;code&gt;DBI&lt;/code&gt; interface for R users. We will go into the package &lt;code&gt;noctua&lt;/code&gt; in the next blog. First here is an example how of to work with AWS Athena when using &lt;code&gt;paws&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Querying to AWS Athena using &lt;code&gt;paws&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# create an AWS Athena object
athena &amp;lt;- paws::athena()

# Submit query to AWS Athena
res &amp;lt;- athena$start_query_execution(
            QueryString = &amp;quot;show Databases&amp;quot;,
            ResultConfiguration = 
                list(OutputLocation = &amp;quot;s3://mybucket/queries/&amp;quot;))

# Get Status of query
result &amp;lt;- athena$get_query_execution(QueryExecutionId = res$QueryExecutionId)

# Return results if query is successful
if(result$QueryExecution$Status$State == &amp;quot;FAILED&amp;quot;) {
  stop(result$QueryExecution$Status$StateChangeReason, call. = FALSE)
} else {output &amp;lt;- 
          athena$get_query_results(
              QueryExecutionId = res$QueryExecutionId,
              MaxResults = 1)}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From initial view it might look daunting however this is exactly the same interface that &lt;code&gt;boto3&lt;/code&gt; provides when working with AWS Athena. The good news is that &lt;code&gt;noctua&lt;/code&gt; wraps all of this and creates the DBI method &lt;code&gt;dbGetQuery&lt;/code&gt; for &lt;code&gt;paws&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;paws&lt;/code&gt; is an excellent R SDK into AWS, so please download &lt;code&gt;paws&lt;/code&gt; and give it ago, I am sure you will be pleasantly surprised like myself.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;paws&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For more examples, the developers of &lt;code&gt;paws&lt;/code&gt; have created some code examples &lt;a href=&#34;https://github.com/paws-r/paws/tree/master/examples&#34;&gt;https://github.com/paws-r/paws/tree/master/examples&lt;/a&gt; and a  documentation website &lt;a href=&#34;https://paws-r.github.io/&#34;&gt;https://paws-r.github.io/&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;botor-https-daroczig-github-io-botor&#34;&gt;&lt;a href=&#34;https://daroczig.github.io/botor/&#34;&gt;&lt;code&gt;botor&lt;/code&gt;&lt;/a&gt; :&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;This R package provides raw access to the ‘Amazon Web Services’ (‘AWS’) ‘SDK’ via the ‘boto3’ Python module and some convenient helper functions (currently for S3 and KMS) and workarounds, eg taking care of spawning new resources in forked R processes. (&lt;a href=&#34;https://daroczig.github.io/botor/&#34;&gt;https://daroczig.github.io/botor/&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When using &lt;code&gt;botor&lt;/code&gt; on AWS Sagemaker, R users can easily interact with all of AWS products in the exact same manner as a Python user. However &lt;code&gt;botor&lt;/code&gt;&amp;rsquo;s convenient helper functions certainly do make the exeperience working on sagemaker. Here is a quick example to demostrate how easy/ useful these helper function are:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Upload iris data.frame to s3 bucket&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(botor)

write_s3(iris, data.table::fwrite, &amp;quot;s3://mybucket/iris.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Read s3 file back into R as a data.frame&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;read_s3(&amp;quot;s3:://mybucket/iris.csv&amp;quot;, data.table::fread)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These convenient helper functions are not limited to just reading/writing data in csv format. They can also be used to upload R models, which can be really useful when wanted to store pre-built models. Here is a quick example of what I like to call a &lt;em&gt;crap&lt;/em&gt; model.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;train &amp;lt;- iris[1:20,1:4]
test &amp;lt;- iris[21:40,1:4]
 
model &amp;lt;- lm(Petal.Width ~., train)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Uploading and downloading R models to S3&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s3_write(model, saveRDS, &amp;quot;s3://mybucket/crap_model.RDS&amp;quot;)
s3_model &amp;lt;- s3_read(&amp;quot;s3://mybucket/crap_model.RDS&amp;quot;, readRDS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is really clear to see how useful &lt;code&gt;botor&lt;/code&gt; is when working with AWS S3.&lt;/p&gt;

&lt;h2 id=&#34;cloudyr-project&#34;&gt;Cloudyr Project:&lt;/h2&gt;

&lt;p&gt;I personally haven&amp;rsquo;t used the AWS cloudyr packages, however I don&amp;rsquo;t want to leave them out. The &lt;a href=&#34;https://cloudyr.github.io/&#34;&gt;cloudyr project&lt;/a&gt; aim is to bring R onto the cloud compute:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The goal of this initiative is to make cloud computing with R easier, starting with robust tools for working with cloud computing platforms.(&lt;a href=&#34;https://cloudyr.github.io/&#34;&gt;https://cloudyr.github.io/&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As I haven&amp;rsquo;t utilised the wide range of packages that the &lt;code&gt;cloudyr project&lt;/code&gt; provides I won&amp;rsquo;t give examples. Please go to the cloudyr github &lt;a href=&#34;https://github.com/cloudyr&#34;&gt;https://github.com/cloudyr&lt;/a&gt; as alot of work has gone into making R easier to work with cloud computing. They have alot of documentation plus they are actively developing R packages to make user experience better.&lt;/p&gt;

&lt;h1 id=&#34;summary&#34;&gt;Summary:&lt;/h1&gt;

&lt;p&gt;I believe that all of these packages are critical if you wish to work with AWS when using R. As R has a SDK &lt;code&gt;paws&lt;/code&gt; for AWS it would be great if AWS adds it to the base image for AWS Sagemaer, as it will allow R developers to utilise AWS products in their AWS sagemaker environments. Alternatively the &lt;code&gt;botor&lt;/code&gt; package would be another package for AWS to concider putting in their AWS Sagemaker image.&lt;/p&gt;
</description>
      
                  <category>R</category>
      
                  <category>paws</category>
      
                  <category>Boto3</category>
      
                  <category>Python</category>
      
      
            <category>RBloggers</category>
      
    </item>
    
    <item>
      <title>RAthena 1.3.0 has arrived</title>
      <link>/post/rathena-1-3-0-has-arrived/</link>
      <pubDate>Sat, 26 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/rathena-1-3-0-has-arrived/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.r-bloggers.com&#34;&gt;RBloggers&lt;/a&gt;|&lt;a href=&#34;http://feeds.feedburner.com/RBloggers&#34;&gt;RBloggers-feedburner&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;recap&#34;&gt;Recap:&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/DyfanJones/RAthena&#34;&gt;&lt;code&gt;RAthena&lt;/code&gt;&lt;/a&gt; is a R package that interfaces into Amazon Athena. However, it doesn&amp;rsquo;t use the standard &lt;code&gt;ODBC&lt;/code&gt; and &lt;code&gt;JDBC&lt;/code&gt; drivers like &lt;code&gt;AWR.Athena&lt;/code&gt; and &lt;code&gt;metis&lt;/code&gt;. Instead &lt;code&gt;RAthena&lt;/code&gt; utilises Python&amp;rsquo;s SDK (software development kit) into Amazon, &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&#34;&gt;&lt;code&gt;Boto3&lt;/code&gt;&lt;/a&gt;. It does this by using the &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;&lt;code&gt;reticulate&lt;/code&gt;&lt;/a&gt; package that provides an interface into Python. What this means is that &lt;code&gt;RAthena&lt;/code&gt; doesn&amp;rsquo;t require any driver installation or setup. That can be particularly difficult when you are considering setting up the ODBC drivers and you are not familiar with how ODBC works on your current operating system. If you wish to use ODBC, RStudio has provided a good user guide &lt;a href=&#34;https://db.rstudio.com/best-practices/drivers/&#34;&gt;Setting up ODBC Drivers&lt;/a&gt; to help set up ODBC drivers on your system. However if you do not wish to go down that route &lt;code&gt;RAthena&lt;/code&gt; might be a good option for you.&lt;/p&gt;

&lt;h1 id=&#34;new-features-in-rathena&#34;&gt;New Features in &lt;code&gt;RAthena&lt;/code&gt;:&lt;/h1&gt;

&lt;p&gt;Anyway, getting back to &lt;code&gt;RAthena&lt;/code&gt; and what does the new update provide. One of the key changes in &lt;code&gt;RAthena&lt;/code&gt; is the method of transferring data to and from AWS Athena. &lt;code&gt;RAthena&lt;/code&gt; now utilising &lt;a href=&#34;https://rdatatable.gitlab.io/data.table/&#34;&gt;&lt;code&gt;data.table&lt;/code&gt;&lt;/a&gt; for this process. The reason for this change is the raw speed &lt;code&gt;data.table&lt;/code&gt;. When transferring data to and from AWS Athena the last thing you want is a bottle neck in R just preparing the data before it even transfers it to AWS Athena. This bottle neck can easily be 50 - 100x longer without the use of &lt;code&gt;data.table&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The next change is &lt;code&gt;bigint&lt;/code&gt;, and how it is converted from AWS Athena to R. In the past &lt;code&gt;RAthena&lt;/code&gt; would just convert &lt;code&gt;integer64&lt;/code&gt; to &lt;code&gt;bigint&lt;/code&gt; when writing to AWS Athena, however it would then convert &lt;code&gt;bigint&lt;/code&gt; back into R as a normal &lt;code&gt;integer&lt;/code&gt;. Which means it is constrained to 32-bit integers. This has now been fixed. When reading &lt;code&gt;bigint&lt;/code&gt; from AWS Athena &lt;code&gt;RAthena&lt;/code&gt; will now convert it into &lt;code&gt;integer64&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;sum-up&#34;&gt;Sum Up:&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;RAthena&lt;/code&gt; now provides a faster method in reading and writing data from AWS Athena (thanks &lt;code&gt;data.table&lt;/code&gt;). With the correct handling of AWS Athena &lt;code&gt;bigint&lt;/code&gt;. So please give &lt;code&gt;RAthena&lt;/code&gt; a try and let me know what you think of the package. Suggestions/Bugs/Enhancements are always welcome and they will help the package to improve: &lt;a href=&#34;https://github.com/DyfanJones/RAthena/issues&#34;&gt;https://github.com/DyfanJones/RAthena/issues&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation-methods&#34;&gt;Installation methods:&lt;/h2&gt;

&lt;p&gt;Just in case you are not aware &lt;a href=&#34;https://cran.r-project.org/web/packages/RAthena/index.html&#34;&gt;&lt;code&gt;Rathena&lt;/code&gt;&lt;/a&gt; is available on the CRAN and GitHub.&lt;/p&gt;

&lt;p&gt;CRAN:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;RAthena&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GitHub development version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;remotes::install_github(&amp;quot;dyfanjones/RAthena&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
      
                  <category>R</category>
      
                  <category>Athena</category>
      
                  <category>Boto3</category>
      
                  <category>Python</category>
      
      
            <category>RBloggers</category>
      
    </item>
    
    <item>
      <title>Athena and R ... there is another way!?</title>
      <link>/post/athena-and-r-there-is-another-way/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/athena-and-r-there-is-another-way/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.r-bloggers.com&#34;&gt;RBloggers&lt;/a&gt;|&lt;a href=&#34;http://feeds.feedburner.com/RBloggers&#34;&gt;RBloggers-feedburner&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro:&lt;/h1&gt;

&lt;p&gt;Currently there are two key ways in connecting to Amazon Athena from R, using the &lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/connect-with-odbc.html&#34;&gt;ODBC&lt;/a&gt; and &lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/connect-with-jdbc.html&#34;&gt;JDBC&lt;/a&gt; drivers. To access the ODBC driver R users can use the excellent &lt;a href=&#34;https://github.com/r-dbi/odbc&#34;&gt;odbc package&lt;/a&gt; supported by Rstudio. To access the JDBC driver R users can either use the &lt;a href=&#34;https://cran.r-project.org/web/packages/RJDBC/index.html&#34;&gt;RJDBC&lt;/a&gt; R package or the helpful wrapper package &lt;a href=&#34;https://github.com/nfultz/AWR.Athena&#34;&gt;AWR.Athena&lt;/a&gt; which wraps the &lt;code&gt;RJDBC&lt;/code&gt; package to make the connection to Amazon Athena through the JDBC driver simpler. These methods are an excellent way for R to connect to Amazon Athena, however is there another way?&lt;/p&gt;

&lt;p&gt;Well glad you asked&amp;hellip;yes there is! Ever since the &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;reticulate package&lt;/a&gt; was developed (by Rstudio) the interface into Python from R has never been simpler. This makes another route into Athena possible! Amazon has developed a Python software development kit (SDK) called &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html?id=docs_gateway&#34;&gt;Boto3&lt;/a&gt;. By using &lt;code&gt;boto3&lt;/code&gt; in combination with the R package &lt;code&gt;reticulate&lt;/code&gt; a new method into accessing Athena can be made possible. Introducing the R package &lt;a href=&#34;https://dyfanjones.github.io/RAthena/&#34;&gt;RAthena&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;rathena&#34;&gt;RAthena:&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What is RAthena?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Rathena&lt;/code&gt; is a R package that creates a DBI (Database Interface) for R, using the R package &lt;a href=&#34;https://dbi.r-dbi.org/&#34;&gt;DBI&lt;/a&gt; and the Python package &lt;code&gt;Boto3&lt;/code&gt; as the backend.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why was RAthena created when there are already methods for connecting to Athena?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;RAthena&lt;/code&gt; was created to provide an extra method to connect to Athena for R users. Nothing more, nothing less.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why is RAthena call RAthena?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Isn&amp;rsquo;t it obvious? Most R packages that interface with a database are called &lt;code&gt;&amp;quot;R&amp;lt;database&amp;gt;&amp;quot;&lt;/code&gt; for example &lt;code&gt;RSQLite&lt;/code&gt;, &lt;code&gt;RPostgreSQL&lt;/code&gt;, etc&amp;hellip; Plus this package is &amp;ldquo;roughly&amp;rdquo; the R equivalent to the superb &lt;code&gt;Python&lt;/code&gt; package &lt;a href=&#34;https://github.com/laughingman7743/PyAthena&#34;&gt;PyAthena&lt;/a&gt;. So calling this package &lt;code&gt;RAthena&lt;/code&gt; seems like the best choice.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;getting-started&#34;&gt;Getting Started:&lt;/h1&gt;

&lt;p&gt;Now lets get into how to actually use &lt;code&gt;RAthena&lt;/code&gt;. I am going to skip over the part were you have to set up an &lt;a href=&#34;https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/&#34;&gt;Amazon Web Services Account&lt;/a&gt; (AWS Acount) and get straight into the good stuff.&lt;/p&gt;

&lt;p&gt;Before working with &lt;code&gt;RAthena&lt;/code&gt;, &lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python 3+&lt;/a&gt; is require. Please install it directly or use the &lt;a href=&#34;https://www.anaconda.com/distribution/&#34;&gt;Anaconda Distribution&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now we have &lt;code&gt;Python 3+&lt;/code&gt; we now need to install &lt;code&gt;Boto3&lt;/code&gt;. If you installed &lt;code&gt;Python 3+&lt;/code&gt; with the Anaconda Distribution I believe &lt;code&gt;Boto3&lt;/code&gt; comes as standard (you can skip &lt;code&gt;boto3&lt;/code&gt; installation step), but for everyone else you can install &lt;code&gt;Boto3&lt;/code&gt; either by the &lt;code&gt;pip&lt;/code&gt; command or the inbuilt installation function in &lt;code&gt;RAthena&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;pip command:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Install &lt;code&gt;RAthena&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;remotes::install_github(&amp;quot;dyfanjones/rathena&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;RAthena&lt;/code&gt; boto3 installation function:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;RAthena::install_boto()
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;usage&#34;&gt;Usage&lt;/h1&gt;

&lt;h2 id=&#34;connecting-to-athena&#34;&gt;Connecting to Athena&lt;/h2&gt;

&lt;p&gt;Now we have everything that is required we are now ready to connect to &lt;code&gt;Athena&lt;/code&gt;. &lt;code&gt;RAthena&lt;/code&gt; provides several method to connect to &lt;code&gt;Athena&lt;/code&gt; ranging from hard-coding credentials to using Amazon Resource Name Roles (ARN roles).&lt;/p&gt;

&lt;h3 id=&#34;hard-coding-method&#34;&gt;Hard-Coding Method:&lt;/h3&gt;

&lt;p&gt;This method isn&amp;rsquo;t recommended as your credentials are hard-coded.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
con &amp;lt;- dbConnect(RAthena::athena(),
                 aws_access_key_id = &amp;quot;YOUR AWS KEY ID&amp;quot;,
                 aws_secret_access_key = &amp;quot;YOUR SECRET ACCESS KEY&amp;quot;,
                 s3_staging_dir = &amp;quot;LOCATION FOR ATHENA QUERY OUTPUT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;&lt;code&gt;s3_staging_dir&lt;/code&gt; requires to be in the format of &lt;code&gt;s3 uri&lt;/code&gt; for example &amp;ldquo;s3://path/to/query/bucket/&amp;rdquo;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;environment-variable-method&#34;&gt;Environment Variable Method:&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;RAthena&lt;/code&gt; supports &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html&#34;&gt;AWS credentials&lt;/a&gt; set into the environment variables to avoid hard-coding. From what I have found out an easy way to set up environment variables (that persists) in R is to use the &lt;code&gt;file.edit&lt;/code&gt; function like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;file.edit(&amp;quot;~/.Renviron&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now you can simply add in your environment variables in the file you are editing for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AWS_ACCESS_KEY_ID = &amp;lt;YOUR AWS KEY ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you have set your environment variables you can connect to Athena in the following method:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
con &amp;lt;- dbConnect(RAthena::athena(),
                 s3_staging_dir = &amp;quot;LOCATION FOR ATHENA QUERY OUTPUT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;aws-profile-names&#34;&gt;AWS Profile Names:&lt;/h3&gt;

&lt;p&gt;Another method is to use AWS Profile Names. AWS profile names can be setup either manually in the &lt;code&gt;~/.aws&lt;/code&gt; directory or by using the &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html&#34;&gt;AWS Command Line Interface (AWS CLI)&lt;/a&gt;. Once you have setup your profile name you can connect to &lt;code&gt;Athena&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Using Default Profile Name:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
con &amp;lt;- dbConnect(RAthena::athena(),
                 s3_staging_dir = &amp;quot;LOCATION FOR ATHENA QUERY OUTPUT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Using Non-Default Profile Name:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
con &amp;lt;- dbConnect(RAthena::athena(),
                 profile_name = &amp;quot;rathena&amp;quot;,
                 s3_staging_dir = &amp;quot;LOCATION FOR ATHENA QUERY OUTPUT&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;arn-roles&#34;&gt;ARN Roles:&lt;/h3&gt;

&lt;p&gt;ARN roles are fairly useful if you need to assume a role that can connect to another AWS account and use the &lt;code&gt;Athena&lt;/code&gt; in that account. Or whether you want to create a temporary connection with different permissions than your current role (&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html&#34;&gt;AWS ARN Documentation&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assuming ARN role credentials before connecting to Athena:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(RAthena)
library(DBI)
assume_role(profile_name = &amp;quot;YOUR_PROFILE_NAME&amp;quot;,
            role_arn = &amp;quot;arn:aws:sts::123456789012:assumed-role/role_name/role_session_name&amp;quot;,
            set_env = TRUE)

# Connect to Athena using ARN Role
con &amp;lt;- dbConnect(athena(),
                s3_staging_dir = &amp;quot;s3://path/to/query/bucket/&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Connect to Athena directly using ARN role:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
con &amp;lt;- dbConnect(athena(),
                  profile_name = &amp;quot;YOUR_PROFILE_NAME&amp;quot;,
                  role_arn = &amp;quot;arn:aws:sts::123456789012:assumed-role/role_name/role_session_name&amp;quot;,
                  s3_staging_dir = &#39;s3://path/to/query/bucket/&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;ARN Roles have a duration timer before they will expire. To change the default you can increase the &lt;code&gt;duration_seconds&lt;/code&gt; parameter from the default 3600 seconds (1 hour).&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;temporary-sessions&#34;&gt;Temporary Sessions:&lt;/h3&gt;

&lt;p&gt;Finally you can create temporary credentials before connecting to &lt;code&gt;Athena&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(RAthena)
library(DBI)

# Create Temporary Credentials duration 1 hour
get_session_token(&amp;quot;YOUR_PROFILE_NAME&amp;quot;,
                  serial_number=&#39;arn:aws:iam::123456789012:mfa/user&#39;,
                  token_code = &amp;quot;531602&amp;quot;,
                  set_env = TRUE)

# Connect to Athena using temporary credentials
con &amp;lt;- dbConnect(athena(),
                s3_staging_dir = &amp;quot;s3://path/to/query/bucket/&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;This method will work for users who have set up &lt;a href=&#34;https://aws.amazon.com/iam/details/mfa/&#34;&gt;Multi-Factor Authentication&lt;/a&gt; (MFA).&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;basic-usage&#34;&gt;Basic Usage&lt;/h2&gt;

&lt;p&gt;Now we have created a connection to &lt;code&gt;Athena&lt;/code&gt; we can ulitise &lt;code&gt;DBI&lt;/code&gt; methods to query &lt;code&gt;Athena&lt;/code&gt; for example:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;All available tables in Athena:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dbListTables(con)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Send Query to Athena&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- dbSendQuery(con, &amp;quot;SELECT * FROM INFORMATION_SCHEMA.COLUMNS&amp;quot;)
dbFetch(res)
dbClearResult(res)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or &amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- dbExecute(con, &amp;quot;SELECT * FROM INFORMATION_SCHEMA.COLUMNS&amp;quot;)
dbFetch(res)
dbClearResult(res)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or &amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;dbGetQuery&lt;/code&gt; wraps sending, fetching and clearing results in one easy step.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dbGetQuery(con, &amp;quot;SELECT * FROM INFORMATION_SCHEMA.COLUMNS&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;You might of noticed that if you have &lt;code&gt;data.table&lt;/code&gt; installed, &lt;code&gt;RAthena&lt;/code&gt; will attempt to return the data as a &lt;code&gt;data.table&lt;/code&gt;. This is to improve speed when larger queries are returned from &lt;code&gt;Athena&lt;/code&gt;. If you don&amp;rsquo;t have &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;RAthena&lt;/code&gt; will return the output as a &lt;code&gt;data.frame&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Get Column information&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- dbSendQuery(con, &amp;quot;SELECT * FROM INFORMATION_SCHEMA.COLUMNS&amp;quot;)
dbColumnInfo(res)
dbClearResult(res)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To learn about what &lt;code&gt;DBI&lt;/code&gt; methods have been implemented in &lt;code&gt;RAthena&lt;/code&gt; please refer to: &lt;a href=&#34;https://dyfanjones.github.io/RAthena/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;intermediate-usage&#34;&gt;Intermediate Usage:&lt;/h2&gt;

&lt;p&gt;It is all very well querying data from &lt;code&gt;Athena&lt;/code&gt; but what is more useful is to upload data as well. &lt;code&gt;RAthena&lt;/code&gt; has addressed this and implemented a method in &lt;code&gt;dbWriteTable&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dbWriteTable(con, &amp;quot;mtcars&amp;quot;, mtcars,
             partition=c(&amp;quot;TIMESTAMP&amp;quot; = format(Sys.Date(), &amp;quot;%Y%m%d&amp;quot;)),
             s3.location = &amp;quot;s3://mybucket/data/&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you have uploaded data into &lt;code&gt;Athena&lt;/code&gt; you can query it in the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dbGetQuery(con, &amp;quot;select * from mtcars&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here are all variable parameters for the &lt;code&gt;dbWriteTable&lt;/code&gt; method:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;conn:&lt;/strong&gt; An AthenaConnection object, produced by dbConnect()&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;name:&lt;/strong&gt; A character string specifying a table name. Names will be automatically quoted so you can use any sequence of characters, not just any valid bare table name.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;value:&lt;/strong&gt; A data.frame to write to the database.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;overwrite:&lt;/strong&gt; Allow overwriting the destination table. Cannot be &amp;lsquo;TRUE&amp;rsquo; if &amp;lsquo;append&amp;rsquo; is also &amp;lsquo;TRUE&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;append:&lt;/strong&gt; Allow appending to the destination table. Cannot be &amp;lsquo;TRUE&amp;rsquo; if &amp;lsquo;overwrite&amp;rsquo; is also &amp;lsquo;TRUE&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;row.names:&lt;/strong&gt; Either TRUE, FALSE, NA or a string. If TRUE, always translate row names to a column called &amp;ldquo;row_names&amp;rdquo;. If FALSE, never translate row names. If NA, translate rownames only if they&amp;rsquo;re a character vector. A string is equivalent to TRUE, but allows you to override the default name. For backward compatibility, NULL is equivalent to FALSE.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;field.types:&lt;/strong&gt; Additional field types used to override derived types.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;partition:&lt;/strong&gt; Partition Athena table (needs to be a named list or vector) for example: c(var1 = &amp;ldquo;2019-20-13&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;s3.location&lt;/strong&gt; s3 bucket to store Athena table, must be set as a s3 uri for example (&amp;ldquo;s3://mybucket/data/&amp;ldquo;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;file.type:&lt;/strong&gt; What file type to store data.frame on s3, RAthena currently supports [&amp;ldquo;csv&amp;rdquo;, &amp;ldquo;tsv&amp;rdquo;, &amp;ldquo;parquet&amp;rdquo;]. &lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;file.type &amp;ldquo;parquet&amp;rdquo; is supported by R package &lt;a href=&#34;https://github.com/apache/arrow/tree/master/r&#34;&gt;&lt;code&gt;arrow&lt;/code&gt;&lt;/a&gt; and will need to be installed separately if you wish to upload data.frames in &amp;ldquo;parquet&amp;rdquo; format.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&amp;hellip;:&lt;/strong&gt; Other arguments used by individual methods.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;tidyverse-usage&#34;&gt;Tidyverse Usage:&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;RAthena&lt;/code&gt; can integrate with the famous R package &lt;a href=&#34;https://github.com/tidyverse/dplyr&#34;&gt;dplyr&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DBI)
library(dplyr)

con &amp;lt;- dbConnect(RAthena::athena(),
                 profile_name = &amp;quot;rathena&amp;quot;,
                 s3_staging_dir = &amp;quot;LOCATION FOR ATHENA QUERY OUTPUT&amp;quot;)

tbl(con, sql(&amp;quot;SELECT * FROM INFORMATION_SCHEMA.COLUMNS&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or if you have already uploaded a table into &lt;code&gt;Athena&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tbl(con, &amp;quot;mtcars&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion:&lt;/h1&gt;

&lt;p&gt;So hopefully this has given you an insight into the up coming package &lt;code&gt;RAthena&lt;/code&gt; and it&amp;rsquo;s usefulness. This package is not meant to replace any of the other packages that connect into &lt;code&gt;Athena&lt;/code&gt; but give another route into &lt;code&gt;Athena&lt;/code&gt; for R users.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Final note:&lt;/strong&gt; &lt;code&gt;RAthena&lt;/code&gt; offers a lot more functionality please check it out at &lt;a href=&#34;https://github.com/DyfanJones/RAthena&#34;&gt;Github&lt;/a&gt;. If you have any suggestions please raise an issue at &lt;a href=&#34;https://github.com/DyfanJones/RAthena/issues&#34;&gt;Github Issues&lt;/a&gt;.&lt;/p&gt;
</description>
      
                  <category>R</category>
      
                  <category>Athena</category>
      
                  <category>Boto3</category>
      
                  <category>Python</category>
      
      
            <category>RBloggers</category>
      
    </item>
    
  </channel>
</rss>